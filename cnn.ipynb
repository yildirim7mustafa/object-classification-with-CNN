{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a42b18",
   "metadata": {},
   "source": [
    "pip install --upgrade tensorflow\n",
    "pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d964d2",
   "metadata": {},
   "source": [
    "# Resimlerin okunması, resim ve etiket dizilerinin oluşturulması aşaması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f528019f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 00:32:24.084303: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55cf4d0",
   "metadata": {},
   "source": [
    "inputBasePath içerisinde her bir sınıf için o sınıf adıyla oluşturulmuş bir klasör vardır ve her klasör içerisinde o sınıfa ait resimler yer almaktadır. bu resimler her analiz adımında yeniden okunup işlenebilir ancak bu okuma sürecini yeniden yeniden yapmamak için resimler bir kereye mahsus okunup, istenirse yeniden boyutlandırılıp, istenirse filtre uygulanıp vs. daha sonra bir numpy array olarak kaydedilir. daha sonraki analiz işlemlerinden direkt bu array okunarak hızlıca işlem yapılabilir. oluştutulan array'ler outputBasePath yoluna kaydedilecek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1efbd4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputBasePath    = r\"/home/yildirim/Jupiter/images\"\n",
    "outputBasePath =  r\"/home/yildirim/Jupiter/imagearrays\" #bu klasörlerin daha önce oluşturulmuş olması gerek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c1da5e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "resimler yeniden boyutlandırılmak istenirse genişlik ve yükseklik değerleri burada tanımlanıyor. özellikle state-of-art modeller resimleri belli ölçülerde daha iyi işliyor. ideal değerleri öğrenip ona göre boyut verilebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a0e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 224\n",
    "image_height = 224 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899649e9",
   "metadata": {},
   "source": [
    "sınıf adlarını tutan bir dizi tanımlanıyor. bu sınıf adları aynı zamanda inputBasePath'te yer alan klasör isimleri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b80045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['cat','dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d9d23f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> cat\n",
      "=> dog\n",
      "X :  244\n",
      "Y :  244\n",
      "X :  (244, 224, 224, 3)\n",
      "Y :  (244,)\n",
      "X :  244\n",
      "Y :  244\n",
      "[ INFO - STAGE1 ]  NUMPY ARRAY CREATION COMPLETED \n",
      " \n"
     ]
    }
   ],
   "source": [
    "os.chdir(inputBasePath) #chdir -> change directory, inputBasePath yoluyla verilen dizine git\n",
    "\n",
    "X = [] # resimleri yani girdileri yani X değerlerini tutmak için dizi\n",
    "Y = [] # etiketleri yani Y değerlerini tutmak için dizi. her bir resmin etiketi içinde yer aldığı klasörün adı zaten\n",
    "\n",
    "i = 0\n",
    "for class1 in classes:\n",
    "  os.chdir(class1) #base yoldan sonra sıradaki sınıfı gösteren klasöre konumlan\n",
    "  print('=> '+class1) #o an üzerinde bulunulan sınıfı (klasör adını) yaz\n",
    "  for files in os.listdir('./'): # nokta mevcut dizini gösteriyor. ./ mevcut dizin altındakiler\n",
    "    img = cv2.imread(files) #dosya yolundan resmi binary array olarak okuma.resmi grayscale almak için ikinci parametreye 0 yazılır cv2.imread(files,0)\n",
    "    img = cv2.resize(img, (image_width,image_height)) #isteğe bağlı olarak resize edilebilir\n",
    "    X.append(img) #resmi oluşturan bit dizisini X'e ekle\n",
    "    Y.append(class1) # bu resmin sınıfı içinde bulunduğu klasör adı. resmin etiketi olarak bunu Y'ye ekle\n",
    "    i = i + 1\n",
    "  os.chdir('..') #bir üst dizine çık. bu sınıfla ve bunu içeren klasörler işimiz bitti\n",
    "  \n",
    "print(\"X : \",len(X))\n",
    "print(\"Y : \",len(Y))\n",
    "\n",
    "X = np.array(X).reshape(-1,image_width,image_height,3) #-1 ile verilen ilk değerin yerinde toplam resim adedi var; \n",
    "                #bu aynı kalacak. diğer parametreler verilen width ve height'e göre ve resmin renkli olduğunu \n",
    "                #belirten 3 ile yeniden şekillendirilecek\n",
    "Y = np.array(Y) #etiket adlarını içeren Y'yi reshape etmeye gerek yok. \n",
    "\n",
    "print(\"X : \",X.shape)\n",
    "print(\"Y : \",Y.shape)\n",
    "\n",
    "print(\"X : \",len(X))\n",
    "print(\"Y : \",len(Y))\n",
    "\n",
    "os.chdir('..') #bir üst dizine daha çıkıp sonra imagearrays klasörüne gidersek zaten outputBasePath'e ulaşmış olacağız\n",
    "os.chdir(\"imagearrays\")\n",
    "# üstteki iki satır yerine bunu direkt chdir(outputBasePath) olarak da yapabilirdik\n",
    "np.save(str(image_width)+'x'+str(image_height)+'_images', X) #diziyi kaydederken dosya adını en x boy_images olarak adlandır.\n",
    "                                                            #'224x224_images' gibi\n",
    "np.save(str(image_width)+'x'+str(image_height)+'_labels', Y) #diziyi kaydederken dosya adını en x boy_labels olarak adlandır.\n",
    "\n",
    "print(\"[ INFO - STAGE1 ]  NUMPY ARRAY CREATION COMPLETED \\n \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580d296a",
   "metadata": {},
   "source": [
    "\n",
    "## Sınıflandırma işlemleri\n",
    "\n",
    "Bu aşamadan sonra daha önce oluşturulan array'ler okunarak işlem yapılacak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abcebecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import MaxPool2D # üstteki MaxPooling2D ile aynı şey. ister onu ister bunu kullan. \n",
    "#kodda ikisi de kullanıldığı için eklendi. yoksa biri ile yapılsaydı da olurdu.\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea965b78",
   "metadata": {},
   "source": [
    "data önce numpy array olarak kaydedilen görüntüleri (data) ve sınıf (label) etiketlerini oku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5fb581c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244, 224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(r\"/home/yildirim/Jupiter/imagearrays/224x224_images.npy\")\n",
    "labels = np.load(r\"/home/yildirim/Jupiter/imagearrays/224x224_labels.npy\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7835d2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat',\n",
       "       'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat',\n",
       "       'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat',\n",
       "       'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat',\n",
       "       'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat',\n",
       "       'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat',\n",
       "       'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat',\n",
       "       'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat',\n",
       "       'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat',\n",
       "       'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat',\n",
       "       'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat',\n",
       "       'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat',\n",
       "       'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat',\n",
       "       'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog',\n",
       "       'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog',\n",
       "       'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog',\n",
       "       'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog',\n",
       "       'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog',\n",
       "       'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog',\n",
       "       'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog',\n",
       "       'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog',\n",
       "       'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog',\n",
       "       'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog',\n",
       "       'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog',\n",
       "       'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog',\n",
       "       'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog',\n",
       "       'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog',\n",
       "       'dog'], dtype='<U3')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b31f4",
   "metadata": {},
   "source": [
    "\n",
    "## Label Encoding\n",
    "\n",
    "array den okunan etiketler orjinal halde, string şeklinde. bunları 0 1 2 şeklinde kodlayacağız yani label encoding yapacağız\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f33d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEn = LabelEncoder() #string olan etiketleri 0 1 2 şeklinde kodla\n",
    "labels = labelEn.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11f479e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb48e41",
   "metadata": {},
   "source": [
    "Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95a7b22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x_train shape: (195, 224, 224, 3)\n",
      "x_test shape: (49, 224, 224, 3)\n",
      "y_train shape: (195, 2)\n",
      "y_test shape: (49, 2)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#veri array'e kaydedilmeden önce reshape edildiğinden array den okununca da düzgün gelir. yeniden reshape etmeye gerek yok\n",
    "#eğer array'e atarken son değer 3 olarak yazılmasaydı burada reshape gerekirdi\n",
    "\n",
    "#data =  data.reshape(-1,image_width , image_height , 3) \n",
    "                                                        \n",
    "\n",
    "\n",
    "\n",
    "# train -test split\n",
    "#%20 test %80 eğitim seti olacak şekilde böl\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size = .20, shuffle = True)\n",
    "\n",
    "\n",
    "print(\n",
    "\"\"\"\n",
    "x_train shape: {}\n",
    "x_test shape: {}\n",
    "y_train shape: {}\n",
    "y_test shape: {}\n",
    "\n",
    "\"\"\".format(x_train.shape, x_test.shape, y_train.shape, y_test.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132b38f7",
   "metadata": {},
   "source": [
    "\n",
    "## Normalizasyon (bu adım opsiyonel)\n",
    "\n",
    "Veriler normalize edilerek piksel değer aralıkları 0-1 aralığına çekilip daha hızlı işlem yapılması sağlanabilir. Normalizasyon işlem hızını arttırır ama her görüntü için başarı artışı getirmeyebilir, belki başarıyı düşürebilir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5000268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mean = np.mean(x_train)\n",
    "x_train_std = np.std(x_train)\n",
    "\n",
    "x_test_mean = np.mean(x_test)\n",
    "x_test_std = np.std(x_test)\n",
    "\n",
    "x_train = (x_train - x_train_mean)/x_train_std\n",
    "x_test = (x_test - x_test_mean)/x_test_std\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ff5b88",
   "metadata": {},
   "source": [
    "\n",
    "### Train - Validation Split\n",
    "\n",
    "%20 test - %10 validation seti olacak şekilde ayır\n",
    "\n",
    "validation datası, modelin eğitimi esnasında train verisini doğrulamak için yani eğitim işlemi esnasındaki test sürecini gerçekleştirmek için kullanılıyor. x_test ve y_test ise eğitim süreci bittikten sonra eğitilen modeli daha önce hiç bilmediği verilerle test etmek için\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58c2eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = .10, shuffle = True,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0d3c2",
   "metadata": {},
   "source": [
    "\n",
    "### Model tanımlama\n",
    "\n",
    "kendimize göre bir model oluşturan ve bunu geri döndüren bir fonksiyon yazalım\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9629b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(input_shape=(image_width ,image_height ,3), num_classes = 2): #parametrelerin varsayılan değerleri var. \n",
    "    #modelin giriş shape'i ve class sayısı= 3                                                                     \n",
    "    #burada oluşturulan model VGG16 mimarisi aslında. değiştirilebilir.\n",
    "\tmodel = Sequential()\n",
    "\tchanDim = -1\n",
    "\n",
    "\tmodel.add(Conv2D(64, (3,3), padding=\"same\",input_shape=input_shape))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# 2.Layer (CONV => RELU => CONV => RELU) * 2 => POOL\n",
    "\tmodel.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# 3.Layer (CONV => RELU => CONV => RELU) * 2 => POOL\n",
    "\tmodel.add(Conv2D(256, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(256, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(256, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# 4.Layer (CONV => RELU => CONV => RELU) * 2 => POOL\n",
    "\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# 5.Layer (CONV => RELU => CONV => RELU) * 2 => POOL\n",
    "\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# 1. TAM BAĞLANTI KATMANI \n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(4096))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t# 2. TAM BAĞLANTI KATMANI \n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(4096))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t# SOFTMAX\n",
    "\tmodel.add(Dense(num_classes))\n",
    "\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd3d9f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bir başka model\n",
    "def model2(input_shape=(image_width ,image_height ,3), num_classes = 2):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding = 'Same',input_shape=input_shape))\n",
    "    model.add(Conv2D(64,kernel_size=(3, 3), activation='relu',padding = 'Same',))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax')) #ikili sınıflama olsaydı sigmoid kullanılırdı. \n",
    "                            #bu durumda zaten num_classes 1 olurdu. yani çıkış nöronu 1 tane olurdu.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85308540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 224, 224, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 112, 112, 64)      73792     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 200704)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               25690240  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,022,914\n",
      "Trainable params: 26,022,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 00:32:26.471516: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = model2()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26333cd",
   "metadata": {},
   "source": [
    "\n",
    "Modeli görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "907400c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /home/yildirim/anaconda3/lib/python3.11/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/yildirim/anaconda3/lib/python3.11/site-packages (from pydot) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydot #görselleştirme için gerekli kütüphane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4a2ad99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63456d18",
   "metadata": {},
   "source": [
    "\n",
    "Optimizer tanımla\n",
    "\n",
    "Eğitim işlemi sonucunda ağın bulduğu sonuç ile gerçekte olması gereken sonuç arasındaki fark ile oluşan hatayı loss function ile hesaplıyoruz. Loss fonksiyonu çoklu sınıflamalarda \"categorical_crossentropy\" , ikili sınıflamada \"binary_crossrntropy\" olarak seçiliyor. Loss hesaplandıktan sonra geriye yayılımla tüm parametrelerin optimize edilmesi gerekiyor. Bu aşamada kullanılan adım uzunluğu \"learning rate\" in (LR) duruma göre adaptif bir şekilde değiştirilmesi sonucu daha verimli kılar. \"Learning rate\" çok küçük olursa işlem uzun sürer, çok büyük olursa hatanın minimum değeri kaçırılabilir. Bu nedenle LR optimize edilmelidir. Bu iş için adaptif momentum optimizer yani \"adam\" optimizer kullanacağız.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7485a3c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258058c6",
   "metadata": {},
   "source": [
    "\n",
    "LR annealer tanımlama\n",
    "\n",
    "Eğitim esnasında monitör edilen parametrede ilerleme olmuyorsa LR değiştirilir. Bu işlemi Keras.callbacks içindeki ReduceLROnPlateau fonksiyonu ile yapabiliriz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f676562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1,  factor=0.5, min_lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f44a5e",
   "metadata": {},
   "source": [
    "\n",
    "modeli derle\n",
    "\n",
    "Loss fonksiyonu çoklu sınıflamalarda \"categorical_crossentropy\" , ikili sınıflamada \"binary_crossentropy\" olarak seçilir. burada üç sınıf olduğu için categorical_crossentropy. çoklu sınıflamada modelin sonundaki sınıflayıcıda (flatten'den sonraki kısım) çıkışta sınıf sayısı kadar nöron olur.\n",
    "\n",
    "İkili sınıflama yapılıyorsa çıkış nöron sayısı tektir. bu tek çıkış 0 veya 1 olarak bir değer verir. bu durumda loss fonksiyonu binary_crossentropy olur.\n",
    "\n",
    "DİKKAT: iki sınıfllı bir veri var/yok şeklinde ise ikili sınıflama uygundur. ama kırmızı-siyah, elma-çilek vs. gibi (yani kırmızı kırmızı değil şeklinde değil veya elma elma değil şeklinde yani var yok halinde değil) ve bu sınıflar 1, 2 gibi kodlanmışsa, çıkışta yine 2 nöron olur ve sınıflamada kategoriktir, binary değildir. bu durum aslında yapılan kurgu ile ilgili.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaded040",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a360d54",
   "metadata": {},
   "source": [
    "\n",
    "epoch ve batch size tanımla\n",
    "\n",
    "epoch = model kaç iterasyon çalışacak batch size = resimler modele bit dizisi matrisleri olarak alınır. her bir adımda kaç resmin bit dizisi alınacak, yani kaç resim alınacak. bir seferde alınan resimler yığın (batch), yığındaki resim sayısı batch size\n",
    "\n",
    "cost fonksiyonu her bir batch için hesaplanır, buna göre geri yayılım yapılır. her bir resim için yapılsaydı süreç uzardı (belki hesap daha hassas olurdu). batch size azaldıkça daha ince hesap yapılır ama süreç uzar, batch size artarsa cost hesabı daha üstünkörü olur, başarı düşebilir. bu nedenle batch size optimum şekilde seçilmeli.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf51f83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epc = 5 \n",
    "bs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36859228",
   "metadata": {},
   "source": [
    "\n",
    "modeli çalıştır\n",
    "\n",
    "modeli fit edince çalışır. modelin her bir aşamasındaki sonuçlar history değişkenine raporlanır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dbac0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "22/22 [==============================] - 35s 2s/step - loss: 0.8684 - accuracy: 0.4857 - val_loss: 0.7030 - val_accuracy: 0.4500 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 37s 2s/step - loss: 0.6961 - accuracy: 0.5314 - val_loss: 0.6946 - val_accuracy: 0.4500 - lr: 1.0000e-04\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 31s 1s/step - loss: 0.6770 - accuracy: 0.6400 - val_loss: 0.6919 - val_accuracy: 0.5500 - lr: 1.0000e-04\n",
      "Epoch 4/5\n",
      " 1/22 [>.............................] - ETA: 31s - loss: 0.6098 - accuracy: 0.8750"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train, batch_size=bs,\n",
    "                              epochs = epc, validation_data = (x_validate,y_validate),\n",
    "                              verbose = 1, callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722bb765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history nin içindeki history değerinin anahtarları raporu alınabilecek değerlerin adlarını gösterir\n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bab6768",
   "metadata": {},
   "source": [
    "\n",
    "Doğruluk grafiklerini çiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b3972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffadd1fa",
   "metadata": {},
   "source": [
    "\n",
    "Hata grafiklerini çiz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7598dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe319490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbfef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(x_test)   \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_test,axis = 1)  #test süreci için Y_true = np.argmax(y_test,axis = 1)\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f572f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_true, Y_pred_classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60fb6b2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "İstenirse eğitilen model daha sonra kullanılmak üzere, hesaplanan ağırlıkları ile kaydedilebilir. bunun için de bir yol tanımlaması yapabiliriz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2ebc0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r\"/home/yildirim/Jupiter/models\") #modeli kaydetmek için \n",
    "model.save('model1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
